---
title: "Organized Backups and Data Persistence"
date: "2025-06-16"
format:
  html:
    toc: true
    html-math-method: katex
    code-fold: false
    embed-resources: true
knitr:
  opts_chunk:
    echo: true
---


Data persistence will tackle two aspects.

1. long-term backups
  - using `pg_dump`
  - automated with `cronjob` and/or diffs
  - tested restoration
  - ... but hopefully never required
2. ad-hoc re-uploads
  - use case: changes in database structure
  - want to be able to drop/create without loss of data
  - crucial: identifier cascades
  - via R scripts


:::{.callout-note}
We might use a [`.pgpass` file](https://stackoverflow.com/a/2893979) for credential handling.
:::


# Long-Term Backups

## continuous

:::{.callout-tip title="Strategy"}
- Store the latest sql
- also store diffs from previous dumps (so that we could go back in time)
:::


```{sh}
#| eval: false

# if not file.exists latest_dump.sql then touch latest_dump.sql

# first: dump the diff to a patch file
pg_dump -U <user> -h <host> -p <port> -d loceval_dev -N tiger -N public -W \
    | diff latest_dump.sql - \
    > $(date +"%Y%m%d")_loceval_diff.patch

# then: patch the changes into `latest`
patch latest_dump.sql -i $(date +"%Y%m%d")_loceval_diff.patch

# # to reverse, apply in reversed order:
# patch -R latest_dump.sql -i $(date +"%Y%m%d")_loceval_diff.patch

```

## monthly

```{sh}
#| eval: false

# first: dump the diff to a patch file
pg_dump -U <user> -h <host> -p <port> -d loceval_dev -N tiger -N public -W \
    > $(date +"%Y%m")_loceval.sql

```

## **TODO** test-restore

After latest structural changes are pushed to production, 
I should attempt to dump/restore the playground data.


# Ad-Hoc Backup/Restore

## connection

```{r libraries-and-paths}
library("dplyr")
library("dbplyr")
library("rprojroot")
library("keyring")
library("configr")
library("DBI")
library("RPostgres")

projroot <- find_root(is_rstudio_project)
working_dbname <- "loceval_dev" 
connection_profile <- "inbopostgis-dev" 

# unless the password is stored in the config,
# you might want to run the following prior to sourcing or rendering this script:
# keyring::key_set("DBPassword", "db_user_password")

source("MNMDatabaseToolbox.R")

```


For safe testing, I will query data from "production", and store it to "dev".

```{r connect-database}
#| eval: false

config_filepath <- file.path("./inbopostgis_server.conf")
db_source <- connect_database_configfile(
  config_filepath,
  database = "loceval",
  profile = connection_profile
)
db_target <- connect_database_configfile(
  config_filepath,
  database = working_dbname,
  profile = connection_profile
)
```


## data re-loading challenge

start simple, with the `Protocols` table.
No foreign keys, static data.

```{r test-table}
#| eval: false

db_table <- DBI::Id(schema = "metadata", table = "Protocols")
protocols_backup <- dplyr::tbl(db_source, db_table) %>%
  collect
glimpse(protocols_backup)

```

Problem is: we need to keep the `protocol_id` persistent.

If we change the protocols, and upload it, the indices will change because they are serials.

```{r}
#| eval: false

rs <- DBI::dbWriteTable(
  db_target,
  db_table,
  protocols_backup,
  row.names = FALSE,
  overwrite = TRUE,
  append = FALSE,
  factorsAsCharacter = TRUE,
  binary = TRUE
)

```

- we cannot append, because that changes the indices
  > Error: COPY returned error : ERROR:  duplicate key value violates unique constraint "Protocols_pkey"
  > DETAIL:  Key (protocol_id)=(1) already exists.
  > CONTEXT:  COPY Protocols, line 1

- we cannot overwrite, because there are dependent tables prohibiting the drop
  > Error: Failed to fetch row : ERROR:  cannot drop table metadata."Protocols" because other objects depend on it
  > DETAIL:  constraint fk_protocols_groupedactivities on table metadata."GroupedActivities" depends on table metadata."Protocols"
  > HINT:  Use DROP ... CASCADE to drop the dependent objects too.


## Solution

:::{.callout-tip title="Strategy"}
We need a framework to dump the whole data and lookup/re-establish connections.
:::

... which is too intricate to be solved in R.


# TODO

*(persistent)*

- handle user permission exceptions 
  - sterr `2>` to separate file
  - check with cronjob or send an e-mail


*(ad-hoc)*

- make sure this works with `sf` and geometries

# ARCHIVE

## notes

- `pg_dumpall ...` -> apply pg_dump to all databases on a server


## database connection

Working out a way to load the config.
Config has the following structure:

```
    [test]
    host = localhost
    port = 5439
    user = test
    database = playground
    password = <optional: the password IN PLAIN TEXT>
```

:::{.callout-warning}
That `.conf`/`.ini` file can contain password in plain text!

- Do not print its content in this notebook.
- Make sure to `.gitignore` it!
:::
