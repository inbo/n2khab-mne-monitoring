#+title: Steps Journal
#+author: Falk Mielke

This file documents the steps I undertook to set up the MNE database structure.

* General
** server setup
SCHEDULED: <2025-05-31 Sat>

+ set up the SQL server on a web hosting service
+ running on arch linux; super user and normal user
+ access via =ssh=:
    + =ssh -p <port> <normaluser>@<host-ip>=
+ postgres database initialized and postgis installed

full details: [[https://github.com/falkmielke/agenda/blob/main/notes/20250602135718-inbopostgis.org]]

#+begin_quote
*Currently, each new IP must be registered in* =/var/lib/postgres/data/pg_hba.conf= *to be able to connect to the database.*
#+end_quote
/cf./ [[https://wiki.archlinux.org/title/PostgreSQL#Optional_configuration]]

** sql user management
SCHEDULED: <2025-05-31 Sat>

... is done directly on the server.

#+begin_src sh :eval no
ssh -p <port> <normaluser>@<host-ip>
su - root
su - postgres
createuser -p <port> --interactive

psql -p <port>
# ALTER USER <user> WITH ENCRYPTED PASSWORD '<password>';
#+end_src

new username needs to be added to =pg_hba.conf=!


** database setup
SCHEDULED: <2025-06-02 Mon>

connect (ssh via keys):
#+begin_src sh :eval no
ssh -p <port> <normaluser>@<host-ip>
su - root
su - postgres
#+end_src


drop-create:
#+begin_src sh :eval no
# dropdb <database> -p <port>
createdb <database> -O <owner> -p <port>
#+end_src


postgis extension:

#+begin_src sh :eval no
psql -U <owner> -h <host-ip> -p <port> -d <database> -W
#+end_src

#+begin_src sql :eval no
CREATE EXTENSION postgis;
CREATE EXTENSION postgis_topology;
CREATE EXTENSION fuzzystrmatch;
CREATE EXTENSION postgis_tiger_geocoder;

#+end_src


** database structure
SCHEDULED: <2025-06-02 Mon>-<2025-06-05 Thu>

A python script is available here:
+ =n2khab-mne-monitoring/900_database_organization/GenerateDatabase.py=

This ideally uses a virtual environment, set up as follows:
#+begin_src sh :eval no
cd <project_folder>
python -m venv .dbinit
source .dbinit/bin/activate
pip install --upgrade pip
pip install --upgrade -r python_requirements.txt
# pip freeze > python_requirements.txt # to feed back updated requirements
#+end_src


Then to run it, with a database connection config file (as described in the script) in place:
#+begin_src sh :eval no
source .dbinit/bin/activate
python GenerateDatabase.py
#+end_src


The script works on "=csv="s which have a fixed structure to define shema's, tables, columns.

An example google file can be found [[https://docs.google.com/spreadsheets/d/1BTtG-A2ASjbF7IhYYb8FDcQLBZtSQbLbElUUYeofHNM/edit?usp=drive_link][here]],
the =csv='s are generated by "File >> Download >> Comma Separated Values (.csv)" for each sheet in the document.
Those files are stored in the =db_structure= subfolder.


* Biotieker, outbound

** setup database
SCHEDULED: <2025-06-05 Thu>

| database name | loceval |
| peer user     | Ward    |

#+begin_src sh :eval no
psql -h <host> -p <port> -U <user> -d <database> -W
#+end_src

** location
SCHEDULED: <2025-06-05 Thu>

*goal:*
+ get a table with point geometry of sample target locations to the database
+ options to filter by date, potentially FAs, ...

Gradual refinement in [[file:100_sample_location_tests.qmd][100_sample_location_tests.qmd]]
