---
title: "Aquatic Habitat Types: Observation Well Placement"
subtitle: "part II: streams"
date: "2025-05-20"
format:
  html:
    toc: true
    html-math-method: katex
    code-fold: false
    embed-resources: true
knitr:
  opts_chunk:
    echo: true
---



```{r libraries}

void <- suppressPackageStartupMessages

conflictRules("n2khab", exclude = c("read_schemes", "read_scheme_types"))
library("stringr")     |> void() # string ragging
library("dplyr")       |> void() # our favorite data wrangling toolbox
library("tidyr")       |> void() # data preparation and rearrangement
library("googledrive") |> void() # google drive data to/fro
library("inbospatial") |> void() # convenience functions for wfs and other queries
library("sf")          |> void() # spatial feature processing
library("terra")       |> void() # spatial raster data
# library("qgisprocess") |> void() # interface to the procedures of our favorite GIS software
library("mapview")     |> void() # show spatial features on a map
library("n2khab")      |> void() # n2khab data and common functions
library("n2khabmon")   |> void() # monitoring schemes for natura2000 habitats

# print sample from sf objects
kableprint <- function(df, show_rows = 5) {
  knitr::kable(df[sample(1:nrow(df), show_rows), ])
}

mapviewOptions(fgb = FALSE) # https://stackoverflow.com/a/65485896


# assert crs 31370
assert_31370 <- function(sf_obj){
  stopifnot(
    "crs 31370" = format(sf::st_crs(sf_obj)) == "BD72 / Belgian Lambert 72"
  )
  return(sf_obj)
}
```


# data

## Assembling Aquatic Habitat Types

### data consistence

```{r datasource-consistency}
#' data source version persistence
#'
#' Manually check data source versions (something to be automated by n2khab
#' package in the future, based on preset versions)
#'
confirm_n2khab_data_consistency <- function() {

  # required for the pipe operator 
  stopifnot("magrittr" = require("magrittr"))

  # the checksums of working data versions (as of 20250501)
  # - watersurfaces_hab: version watersurfaces_hab_v6
  # - habitatstreams: version habitatstreams_2023
  # - habitatsprings: version habitatsprings_2020v2
  # - flanders: version "flanders_2018-05-16"
  reference_checksum <- c(
    flanders.dbf = "d21a599325723682",
    flanders.prj = "2f10404ffd869596",
    flanders.shp = "72fff53084b356be",
    flanders.shx = "1880e141bbcdc6ca",
    habitatsprings.geojson = "7268c26f52fcefe4",
    habitatstreams.dbf = "dee7a620e3bcae0a",
    habitatstreams.lyr = "a120f92d80c92a3a",
    habitatstreams.prj = "7e64ff1751a50937",
    habitatstreams.shp = "5a7d7cddcc52c5df",
    habitatstreams.shx = "b2087e6affe744f4",
    habitatstreams.sld = "2f192b84b4df99e9",
    watersurfaces_hab.gpkg = "e2920c4932008387"
  )
    
  # for comparison: checksums of current files on disk
  status_checksum <- file.path(
      n2khab::locate_n2khab_data(),
      c(
        "20_processed/watersurfaces_hab",
        "10_raw/habitatsprings",
        "10_raw/habitatstreams",
        "10_raw/flanders"
      )
    ) %>%
    list.files(full.names = TRUE) %>%
    n2khab::xxh64sum()
    
  # per filename, check whether checksums match
  check_identical_checksum <- function (filename) {

    # the check
    file_check <- identical(
        reference_checksum[filename],
        status_checksum[filename]
      )

    # more verbose error upon mismatch
    if (!file_check) {
      message(paste0(
        "ERROR: file `",
        filename,
        "` changed on disk.",
        collapse = "") )
      }

    # stop or return TRUE
    return(is.null(
      stopifnot(file_check)
    ))
    
  }

  # check all files
  check <- all(sapply(names(reference_checksum), FUN = check_identical_checksum))

  # confirm correctness of all n2khab data files
  if (check) message("All n2khab data files match the recorded state.")
  
} # /confirm_n2khab_data_consistency


# apply the function
confirm_n2khab_data_consistency()

```


### Streams

Temporary approach to generate `segm_3260` (i.e. it will miss a part and some may be false positives)
(unit ID defined by `unit_id`)

```{r load-streams}
# read_watercourse_100mseg(element = "lines")[habstream, ] %>%
#   mapview()
# read_watercourse_100mseg(element = "points")[habstream, ] %>% 
#   mapview()
# read_habitatstreams() %>%
#   mapview()

# habitat 3260 from
#     Biologische Waarderingskaart en Natura 2000 Habitatkaart
#     https://doi.org/10.21436/inbor.96375305
# ... are the streams
habstream <- read_habitatstreams()

# for those streams, we use the 100m line segments
# applying spatial supsetting (intersect!) with sf_x[sf_y, ]
#   not well documented in https://r-spatial.github.io/sf/reference/sf.html
#   -> geocomputation with R https://r.geocompx.org/spatial-operations#spatial-subsetting
#   habstream <- read_habitatstreams()
#   seg_all <- read_watercourse_100mseg(element = "lines")
#   seg_reference <- seg_all[habstream, , op = sf::st_intersects]
#   seg_test <- seg_all[lengths(sf::st_intersects(seg_all, habstream, sparse = TRUE)) > 0, ]
#   identical(seg_reference, seg_test)
segm_3260 <-
  read_watercourse_100mseg(element = "lines")[habstream, ] %>%
  unite(unit_id, vhag_code, rank) # tidyr::unite string concatenation

kableprint(segm_3260) # unique identifier for line segments

```

## load the sample


### google authentification

Currently, the latest version of the sample is distributed via an `.RData` file on the google drive.

```{r google-auth}
# Setup for googledrive authentication. Set the appropriate env vars in
# .Renviron and make sure you ran drive_auth() interactively with these settings
# for the first run (or to renew an expired Oauth token).
# See ?gargle::gargle_options for more information.
google_drive_init <- function() {
  if (Sys.getenv("GARGLE_OAUTH_EMAIL") != "") {
    options(gargle_oauth_email = Sys.getenv("GARGLE_OAUTH_EMAIL"))
  }
  if (Sys.getenv("GARGLE_OAUTH_CACHE") != "") {
    options(gargle_oauth_cache = Sys.getenv("GARGLE_OAUTH_CACHE"))
  }
}

# tipps for paranoid linux terminal users (non-interactive R):
# - point your oauth cache to a tomb https://dyne.org/tomb
# - do not forget to open the tomb prior to starting the R session

google_drive_init()
```



### load/restore sample data

Download the sample data (unless it is already there).

```{r sample-data-download}
# latest (20250506):
#   target_sample_filepath <- file.path("./data", "objects_for_aq_piezometers_panfl_pan5.RData")
#   googledrive::as_id("1Z93w-C3XRQ8756W3835JPfxggGEstjKR"),


force_reload_sample <- FALSE
target_sample_filepath <- file.path("./data", "objects_for_aq_piezometers_panfl_pan5.RData")

if (force_reload_sample || !file.exists(target_sample_filepath)) {
  googledrive::drive_download(
    googledrive::as_id("1Z93w-C3XRQ8756W3835JPfxggGEstjKR"),
    path = target_sample_filepath,
    overwrite = TRUE
  )
}

# deprecated: 
#   target_sample_filepath <- file.path("./data", "objects_for_aq_piezometers_panfl_pan5.RData")
#   googledrive::as_id("1Z93w-C3XRQ8756W3835JPfxggGEstjKR"),
#   target_sample_filepath <- file.path("./data", "objects_panflpan5.RData")
#   googledrive::as_id("1a42qESF5L8tfnEseHXbTn9hYR1phqS-S"),


# load the data into a new environment
env_extradata <- new.env()
load(target_sample_filepath, envir = env_extradata)
ls(envir = env_extradata)

for (var in c(
  "units_non_cell_n2khab_grts",
  "stratum_units_non_cell_n2khab",
  "scheme_moco_ps_stratum_sppost_spsamples_spares_sf"
  )) {
  tryCatch(
  {stopifnot(exists(var, envir = env_extradata))},
  error = function(wrnmsg) {
    message(paste0(
      "The variable ", var,
      " does not exist in environment `env_extradata`.",
      collapse = "")
    )
  }
  )
}

```

(adjusted to read full POC `.RData`, [see here](https://github.com/inbo/n2khab-mne-design/blob/7a08ab9d36669d3a5b64d12b8bc35ff7c7a6a5d1/100_design_common/010_prototyping_sampling_and_revisit_design/helper_scripts/support_dcp_and_fieldwork.R))


restore sample data structure
Below object can be used to filter the foregoing geospatial objects, taking
into account that: rows with ...

- `sample_support_code == watersurface` relate to the IDs in `wsh_pol`
- `sample_support_code == watercourse_segment` relate to the IDs in `segm_3260`
- `sample_support_code == spring` relate to the IDs in `habspring_units_aquatic`

```{r sample-data-join}

stratum_units_grts_aquatic_gw_spsamples_spares <-
  # units per stratum:
  get("stratum_units_non_cell_n2khab", envir = env_extradata) %>%
  # joining GRTS address per unit. A few non-unique GRTS addresses exist, hence
  # 'many-to-one'. See further.
  inner_join(
    get("units_non_cell_n2khab_grts", envir = env_extradata),
    join_by(sample_support_code, unit_id),
    relationship = "many-to-one",
    unmatched = "error"
  ) %>%
  filter(
    # other 'non-cell' types exist so these must be dropped:
    sample_support_code %in% c(
      "watersurface",
      "watercourse_segment",
      "spring"
    ),
    # terrestrial spring units must also be excluded:
    unit_id %in% habspring_units_aquatic$unit_id |
      sample_support_code != "spring"
  ) %>%
  rename(grts_address_final = grts_address) %>%
  # join with samples ('sample_status' defines whether location is 'in the
  # sample' or is a 'spare unit' (spare units = a bunch of 'next' GRTS addresses
  # in the available GRTS series for a stratum))
  inner_join(
    get(
      "scheme_moco_ps_stratum_sppost_spsamples_spares_sf",
      envir = env_extradata
    ) %>%
      st_drop_geometry() %>% # geom will be used below
      # only use the samples of groundwater schemes
      filter(str_detect(scheme, "^GW")) %>%
      rename(grts_address_drawn = grts_address) %>%
      # collapse module combos and schemes; hereby select the 'prior'
      # sample_status ("in_sample") across module combos and schemes:
      summarize(
        sample_status = sample_status %>% droplevels() %>% levels() %>%  first(),
        .by = c(
          stratum,
          grts_address_drawn,
          grts_address_final
        )
      ) %>%
      mutate(sample_status = factor(sample_status)),
    join_by(stratum, grts_address_final),
    # A few non-unique GRTS addresses exist, hence 'many-to-one'. We will apply
    # a quick-fix below to meet the requirement of 'one unit sampled per GRTS
    # address', but at least the selection will need further alignment with the
    # (likewise) MHQ solution (to be continued).
    relationship = "many-to-one",
    unmatched = "drop"
  ) %>%
  arrange(sample_support_code, stratum, grts_address_drawn, unit_id) %>%
  # for now, de-duplicate units with the same GRTS address by selecting the 1st
  slice(1, .by = c(stratum, sample_support_code, grts_address_final)) %>%
  select(-grts_address_drawn)


# grts address and stratum of all units which are in the target category
# (i.e. "watersurface", "watercourse_segment", "non-terrestrial spring")
kableprint(stratum_units_grts_aquatic_gw_spsamples_spares)

```


::: {.callout-caution}
REMINDER:
we de-duplicated units with the same GRTS address by selecting the 1st.
:::


This was an erroneous attempt: `scheme_moco_ps_stratum_sppost_spsamples_spares_sf` is an sf object, but it refers to centres of the GRTS grid. 
Instead, we would prefer to work on centroids of the water surface polygons

```{r recover-geometry-obsolete}
#| eval: false

geometry_link <- get(
    "scheme_moco_ps_stratum_sppost_spsamples_spares_sf",
    envir = env_extradata
  ) %>%
  assert_31370() %>% 
  select(grts_address) %>%
  distinct

data_obsolete <- geometry_link %>%
  right_join(
    stratum_units_grts_aquatic_gw_spsamples_spares,
  by = join_by(grts_address == grts_address_final),
  relationship = "one-to-many",
  unmatched = "drop"
  )

# mapview(data_obsolete)

# for comparison
data_pol <- data_obsolete %>%
  sf::st_drop_geometry() %>%
  inner_join(
    wsh_pol,
    join_by(unit_id == polygon_id),
    relationship = "many-to-many",
    unmatched = "drop"
  ) %>%
  sf::st_as_sf()
mapview(data_pol)

```

Hence, we better start from `wsh_pol`:

```{r recover-geometry}

watersurfaces_polygons <- stratum_units_grts_aquatic_gw_spsamples_spares %>% 
  filter(sample_support_code == "watersurface") %>% 
  select(unit_id, grts_address_final, sample_status) %>% 
  distinct() %>% 
  left_join(
    wsh_pol,
    join_by(unit_id == polygon_id),
    relationship = "many-to-one",
    unmatched = "drop"
  ) %>%
  sf::st_as_sf()

# mapview(watersurfaces_polygons)
```


```{r polygons-to-centroids}
watersurfaces_data <- watersurfaces_polygons %>%
  sf::st_centroid() %>%
  # sf::st_point_on_surface() %>%
  suppressWarnings()

# mapview(watersurfaces_data)
```



# Application to Streams and Springs

We have other types of water bodies.

```{r streams-and-springs}
stratum_units_grts_aquatic_gw_spsamples_spares %>%
  count(sample_support_code) %>%
  # sf::st_drop_geometry() %>%
  knitr::kable()
```

```{r obsolete-datasource}
#| eval: false

geometry_link <- get(
    "scheme_moco_ps_stratum_sppost_spsamples_spares_sf",
    envir = env_extradata
  ) %>%
  # sf::st_transform(31370) %>% 
  assert_31370() %>% 
  select(grts_address) %>%
  distinct


data_obsolete <- geometry_link %>%
  right_join(
    stratum_units_grts_aquatic_gw_spsamples_spares,
  by = join_by(grts_address == grts_address_final),
  relationship = "one-to-many",
  unmatched = "drop"
  )

```

## stream test data

```{r stream-testing}
#| eval: true
# stratum_units_grts_aquatic_gw_spsamples_spares %>% 


stream_test_data <- 
  segm_3260 %>% 
    filter(
      stringr::str_detect(unit_id, "^9574_"),
      unit_id > "9574_218778"
    ) %>%
  right_join(
    stratum_units_grts_aquatic_gw_spsamples_spares,
    by = join_by(unit_id),
    relationship = "one-to-many",
    unmatched = "drop"
  ) %>% 
  filter(sample_support_code == "watercourse_segment") %>%
  arrange(unit_id)

location_code <- "9574_218821"
test_location <- stream_test_data %>%
  filter(unit_id == location_code)

mapview(stream_test_data)
```


```{r test-stream-plot-dhmv}

xy <- as.data.frame(
    sf::st_coordinates(stream_test_data)
  ) %>%
  rename_with(tolower)

margin <- 256 # m
flow_cellsize <- 32 # m
bbox <- sf::st_bbox(
   c(xmin = min(xy["x"]) - margin,
     xmax = max(xy["x"]) + margin,
     ymin = min(xy["y"]) - margin,
     ymax = max(xy["y"]) + margin
     ),
   crs = sf::st_crs(31370)
)
test_raster <- inbospatial::get_coverage_wcs(
  wcs = "dhmv",
  bbox = bbox,
  layername = "DHMVII_DTM_1m",
  version = "2.0.1",
  wcs_crs = "EPSG:31370",
  resolution = 1
)

# plot map
plot(test_raster, col = gray.colors(256)
     # ylab = sprintf("cluster %i (%s)", cluster_idx, regions)
     )
points(xy[["x"]], xy[["y"]], pch = 21, col = "black")
points(xy[["x"]], xy[["y"]], pch = 16, col = "yellow")
# title(sprintf("cluster %i", cluster_idx))


```

```{r stream-dhmv}

test_buffer <- test_location %>%
  sf::st_buffer(margin) 
sub_raster <- terra::crop(test_raster, sf::st_bbox(test_buffer))

plot(sub_raster, col = gray.colors(256))
points(
  sf::st_coordinates(test_location)[1,"X"],
  sf::st_coordinates(test_location)[1,"Y"],
  pch = 16, col = "yellow")

calculate_flow_direction(
    test_location,
    flow_range = 256, flow_cellsize = 32,
    save_plot_filepath = here::here("figures", sprintf("%s.png", location_code)))

```

In this special case, flow direction might be useful for the stream data point;
However, it is not clear whether/how this will generalizes. 


## stream data preview

- lines or points, and where to get them - that is the question!

```{r lines-or-points}
#| eval: false

stream_testpoints <- read_watercourse_100mseg(element = "points") %>% 
  filter(vhag_code == 9574)
stream_testlines <- read_watercourse_100mseg(element = "lines") %>% 
  filter(vhag_code == 9574)

mapview(stream_testpoints, col.regions = "brown") +
    mapview(stream_testlines, col.regions = "steelblue")

```

Indeed, `read_watercourse_100mseg(element = "lines")` seems to be more accurate.


## stream flow maths (I): points

Streams flow from source to sea, 
and the 100m segments are a severe simplification.

Back to the raw data:

```{r stream-raw-data}
# mapview(habstream)
stream_points <- read_watercourse_100mseg(element = "points")
stream_lines <- read_watercourse_100mseg(element = "lines") 

test_stream_points <- stream_points %>%
  filter(vhag_code == 9574)
test_stream_lines <- stream_lines %>%
  filter(vhag_code == 9574)

mapview(test_stream_points, col.regions = "brown") +
    mapview(test_stream_lines, col.regions = "steelblue")

```

Rank: goes in "upstream" direction (water source: highest rank)

- <https://github.com/inbo/n2khab/blob/main/R/read_watercourses.R>
- <https://github.com/inbo/n2khab-preprocessing/blob/main/src/generate_watercourse_100mseg/10_generate_watercourse_100mseg.Rmd>


Maths refresher:

- <https://www.cs.toronto.edu/~mangas/teaching/320/slides/CSC320L04.pdf>
- <https://math.libretexts.org/@go/page/589>
- possibly Taylor series
- possibly arc-length-parametrization


We require:

- flow direction
- tangent
- normal
- curve forward/backward 
  - (projection onto normal)
  - "How much of the normal we must add to the tangent to approximate the tangent at t+dt".



```{r stream-curve-retrieval}
## for testing:
# vhag <- 9574
# segment_rank <- 218821

# extract a single stream from the 100m watercourse segments
get_stream_pointcurve <- function(vhag, segment_rank) {

  # stream_points <- read_watercourse_100mseg(element = "points")

    
  # filter the points of interest
  target_stream_points <- stream_points %>%
    filter(vhag_code == as.numeric(vhag))

  # join them as a curve
  stream_curve <- as.data.frame(
    cbind(target_stream_points$rank, sf::st_coordinates(target_stream_points))
  )  
  names(stream_curve) <- c("rank", "x", "y")

  # sort by "rank", i.e. point number
  stream_curve$rank <- stream_curve$rank - segment_rank
  stream_curve <- stream_curve %>% arrange(rank)

  return(stream_curve)
}

# quick-plot a curve
plot_stream_curve <- function(stream_curve) {

  stopifnot("ggplot2" = require("ggplot2"))
  stream_curve %>%
    ggplot(ggplot2::aes(x = x, y = y)) +
      ggplot2::geom_line(stat = 'summary', fun = 'mean') +
      ggplot2::geom_point(aes(color = rank))
}


# test plot
test_curve <- get_stream_pointcurve(vhag = 9574, segment_rank = 218821)
plot_stream_curve(test_curve)

```



```{r stream-tangents}

# the tangent at each segment point of the watercourse
get_stream_tangent <- function(
    stream_curve,
    normed = FALSE,
    append = FALSE,
    second = FALSE
    ) {
  
  # first derivative using splines
  # https://stackoverflow.com/a/61287125
  stopifnot("pspline" = require("pspline"))
  t <- -stream_curve$rank # ! inverted: water flow directed downstream
  x <- stream_curve$x
  y <- stream_curve$y

  if (length(t) < 3) {
    stream_curve$tx <- c(diff(x), NA)
    stream_curve$ty <- c(diff(y), NA)
  } else {
    stream_curve$tx <- predict(sm.spline(t, x), t, 1)
    stream_curve$ty <- predict(sm.spline(t, y), t, 1)
  }

  # optionally append second derivative
  if (second) {
    stream_curve$tx2 <- predict(sm.spline(t, x), t, 2)
    stream_curve$ty2 <- predict(sm.spline(t, y), t, 2)
  }

  # optionally normalize 
  tangent_norm <- function(x, y) sqrt((x**2) + (y**2))
  stream_curve$nt <- tangent_norm(stream_curve$tx, stream_curve$ty)

  if (normed) {
    stream_curve$tx <- stream_curve$tx / stream_curve$nt
    stream_curve$ty <- stream_curve$ty / stream_curve$nt

    if (second) {
      n2 <- tangent_norm(stream_curve$tx2, stream_curve$ty2)
      stream_curve$tx2 <- stream_curve$tx2 / n2
      stream_curve$ty2 <- stream_curve$ty2 / n2
    }
  }
    
  # return appended or directly ("inplace = False")
  if (append) return(stream_curve)
  if (second) return(stream_curve[, c("rank", "tx2", "ty2")])
  return(stream_curve[, c("rank", "tx", "ty")])
}


get_stream_tangent(
  test_curve,
  normed = FALSE,
  append = FALSE,
  second = TRUE
)

```


```{r stream-normal}

# calculate the normals, based on tangents
# normals are defined as -π/2 rotation (ccw orthogonal) of the tangent
get_normal <- function(
    stream_curve,
    normed = FALSE,
    append = FALSE
    ) {

  # ensure that the tangent is calculated
  stream_curve <- get_stream_tangent(
    stream_curve,
    normed = normed,
    append = TRUE,
    second = FALSE
  )
    
  # ... and extract the tangent
  tx <- stream_curve$tx
  ty <- stream_curve$ty

  # list of vectors for lapply
  tangents <- lapply(1:length(tx), FUN = function(t) c(tx[t], ty[t]))  

  # conventional rotation -> normal
  rotate_90_ccw <- matrix(c(
     cos(-pi/2), sin(-pi/2),
    -sin(-pi/2), cos(-pi/2)
    ), ncol =2)
  normals <- bind_rows(lapply(
    1:length(tx),
    FUN = function(t) as.data.frame(tangents[[t]] %*% rotate_90_ccw)
  ))
  names(normals) <- c("nx", "ny")

  # head(cbind(stream_curve, normals)) # cbind creates duplicate cols
  if (append) {
    # stream_curve <- stream_curve %>% select(-nx, -ny)
    stream_curve$nx <- normals$nx
    stream_curve$ny <- normals$ny
    return(stream_curve)
  }

  return(normals)
}


get_normal(
  test_curve,
  normed = FALSE,
  append = FALSE
)


```


```{r stream-curvature}

# get curvature or curvature direction for a line segment
# optionally smoothed
# direction is coded as curvature sign (-1: left turn, +1: right turn) but with 0: NA
get_curvature_direction <- function(stream_curve, direction = TRUE, smooth = NA) {

  # for the dot product
  stopifnot("geometry" = require("geometry"))

  # certainly calculate tangents
  stream_normal <- get_normal(
    stream_curve,
    normed = TRUE,
    append = FALSE
  )

  # numeric difference vector
  dx <- diff(stream_curve$x)
  dy <- diff(stream_curve$y)

  # normalize differentials
  d2_norm <- function(x, y) sqrt((x**2) + (y**2))
  l <- d2_norm(dx, dy)
  dx <- dx / l
  dy <- dy / l

  # tangents and normals
  tx <- stream_curve$tx[1:length(dx)]
  ty <- stream_curve$ty[1:length(dy)]
  nx <- stream_normal$nx[1:length(dx)]
  ny <- stream_normal$ny[1:length(dy)]

  # connection vector between tangent and difference vector
  ux <- dx - tx
  uy <- dy - ty

  # scalar of the connection vector onto the normal
  curvatures <- c(sapply(
    1:length(l),
    FUN = function(t) unlist(geometry::dot(c(ux[t], uy[t]), c(nx[t], ny[t])))
  ), NA)

  # optional: smoothing by Gaussian-weighted average
  if (!is.na(smooth)) {
    curvatures <- smoother::smth.gaussian(curvatures, alpha = smooth)
    
  }
  
  # either return the direction...
  if (direction) {
    # (-1: left turn, 0: NA, +1: right turn)
    dirn <- (2*as.numeric(curvatures < 0)) - 1
    dirn[is.na(dirn)] <- 0
    return(dirn)
  }

  # ... or the curvature
  return(curvatures)
    
}

get_curvature_direction(
  test_curve,
  direction = TRUE
)

```


```{r stream-all-curve-measures}

get_all_curve_measures <- function(
    stream_curve,
    normed = TRUE,
    smooth = NA
    ) {

  # numeric difference
  stream_curve$dx <- c(diff(stream_curve$x), NA)
  stream_curve$dy <- c(diff(stream_curve$y), NA)

  # tangent
  stream_curve <- get_stream_tangent(
    stream_curve,
    normed = normed,
    append = TRUE,
    second = FALSE
  )
  
  # normal
  stream_curve <- get_normal(
    stream_curve,
    normed = normed,
    append = TRUE
  )

  # curvature and curvature direction
  stream_curve$curv <- get_curvature_direction(stream_curve, direction = FALSE, smooth = NA)
  stream_curve$dirn <- get_curvature_direction(stream_curve, direction = TRUE, smooth = NA)
  stream_curve$curv_smth <- get_curvature_direction(stream_curve, direction = FALSE, smooth = smooth)
  stream_curve$dirn_smth <- get_curvature_direction(stream_curve, direction = TRUE, smooth = smooth)

  # head(stream_curve)
  return(stream_curve)

}


test_curve <- get_all_curve_measures(
  test_curve,
  normed = TRUE,
  smooth = 5
)

knitr::kable(head(test_curve))

# tangent_norm <- function(sc) sqrt((sc$tx**2) + (sc$ty**2))
# print(tangent_norm(stream_tangent))


```



```{r plot-stream-direction-flow}

plot_stream_flowdirection <- function(
    _curve,
    scale = 64
  ) {

  x <- _curve$x
  y <- _curve$y
  tx <- _curve$tx * scale
  ty <- _curve$ty * scale
  tx2 <- _curve$tx2 * scale
  ty2 <- _curve$ty2 * scale
  nx <- _curve$nx * scale
  ny <- _curve$ny * scale
  curv <- _curve$curv
  curv_smth <- _curve$curv_smth
  dirn <- _curve$dirn
  dirn_smth <- _curve$dirn_smth
  nx <- nx * dirn_smth
  ny <- ny * dirn_smth
  nz <- !as.logical(as.integer(nx == 0) * as.integer(ny == 0))
  # col <- as.integer(dirn)+1
  color <- as.integer(dirn_smth[nz])+3
  
  
  plot(x, y)
  graphics::arrows(x, y, x+tx, y+ty, col = "darkgray", length = 0.1)
  # graphics::arrows(x, y, x+nx, y+ny, col = "lightblue", length = 0.1)
  # graphics::arrows(x-tx2, y-ty2, x+tx2, y+ty2, col = "lightblue", length = 0.1)
  graphics::arrows(
    x[nz], y[nz],
    x[nz] + nx[nz], y[nz] + ny[nz],
    col = color, length = 0.1
  )
}

plot_stream_flowdirection(test_curve)

```

Summary: we calculated

- the tangent (i.e. flow direction)
- the curvature (optionally smoothed)
- the direction (i.e. side, optionally smoothed)


## stream flow maths (I): lines

The `lines` stream data source has a finer resolution.
Here I will adapt the functions from above.


```{r streamline-curve}
# vhag <- 9574

# extract a single stream from the 100m watercourse segments
get_stream_linecurve <- function(vhag, segment_rank = 0) {

  # stream_lines <- read_watercourse_100mseg(element = "lines")
    
  # filter the points of interest
  target_stream_points <- stream_lines %>%
    filter(vhag_code == as.numeric(vhag))

  rank <- target_stream_points$rank
  coords <- data.frame(sf::st_coordinates(target_stream_points))
  coords$sequence <- 1:nrow(coords)

  # join them as a curve
  stream_curve <- as.data.frame(
      cbind(rank, 1:length(rank))
    ) %>%
    setNames(c("rank", "L1")) %>% 
    left_join(coords, join_by(L1))
  names(stream_curve) <- c("rank", "lseq", "x", "y", "sequence")

  # sort by "rank", i.e. point number
  stream_curve$rank <- stream_curve$rank - segment_rank
  stream_curve <- stream_curve %>% arrange(rank, sequence)

  return(stream_curve)
}


# test plot
test_curve <- get_stream_linecurve(vhag = 9574, segment_rank = 218821) %>%
    filter(rank > 20)


test_curve %>%
  ggplot(aes(x = x, y = y)) +
    geom_line() +
    geom_point(aes(color = rank))

head(test_curve)

plot(test_curve$x, test_curve$y) + lines(test_curve$x, test_curve$y)


test_curve %>%
  ggplot(aes(x = x, y = y)) +
    geom_path() +
    geom_point(aes(color = rank))

```

Order of points is ~~horribly wrong~~ totally correct.

:::{.callout-warning}
The problem was in ggplot.

:::



```{r correct-rank-series}

# curve <- test_curve

correct_curve_arrangement <- function(curve, coordinate_columns = NA) {

  # iterate points (downstream)
  # cross-distance of downstream points
  # p = calculate mean diffvector of previous n points
  # n = normal <- rotate normed(p) by π/2
  # d = diffvector to next points
  # l = length projection to normal
  # minimize Euclid(c(l, d))

  # alternative strategy: rotate xy all the time to direction

  # curve <- data.frame(x = c(0, 1., 2.5, 1.8), y = c(0.0, 1., 2.0, 1.5))
  # curve <- test_curve

  if (any(is.na(coordinate_columns))) {
    coordinate_columns <- c("x", "y")
  }

  # use only coordinates
  xy <- as.matrix(curve[coordinate_columns])
  xy <- data.frame(sweep(xy, 2, xy[1,]))

  xy$idx <- NA
  xy$run <- 1:nrow(xy)
    
  Euclid <- function (x, y) sqrt(x^2 + y^2)
  vectornorm <- function(vec) sqrt(sum(sapply(1:length(vec), FUN = function(v) vec[v]^2)))
  # vectornorm(c(0, 1, 1, 2))
  normed_vector <- function(vec) vec / vectornorm(vec)
  # normed_vector(c(0, 1, 1, 2))
  # vectornorm(normed_vector(c(0, 1, 1, 2)))
    
  cross_difference <- function(vec) outer(X = vec, Y = vec, FUN = function(X, Y) Y - X )
  cross_distance <- function(x, y) Euclid(cross_difference(x), cross_difference(y)) 

  project_onto <- function(vec1, vec2) vec1 %*% vec2

  rotate_90_ccw <- matrix(c(
     cos(-pi/2), sin(-pi/2),
    -sin(-pi/2), cos(-pi/2)
    ), ncol =2)


  # cross distances
  cdists <- cross_distance(
    curve[[coordinate_columns[1]]],
    curve[[coordinate_columns[2]]]
  )
    
  # the first two points are set; they give the direction.
  xy[1, "idx"] <- 1
  xy[2, "idx"] <- 2

    
  for (i in 3:14) {
  # for (i in 3:(nrow(xy))) {
    # i <- 3
    # i <- 4
    # we sit on point `i-1`, and want to find the best consecutive for `i`

    set_points <- xy[!is.na(xy$idx), ]

    one_back <- set_points[set_points$idx == i-1, coordinate_columns]
    two_back <- set_points[set_points$idx == i-2, coordinate_columns]
      
    next_points <- xy[is.na(xy$idx), ]
    next_dists <- cdists[xy$run == i-1, is.na(xy$idx)]

    step_vector <- as.matrix(one_back - two_back)

    if (vectornorm(step_vector) != 0){
      step_normal <- normed_vector(as.matrix(step_vector) %*% rotate_90_ccw)
      putative_steps <- sweep(
          as.matrix(next_points[,coordinate_columns]), 2, as.matrix(one_back))
      projections <- t(abs(as.matrix(putative_steps) %*% t(step_normal)))
    } else {
      projections <- rep(0, length(next_dists))
    }

    # projections <- rep(0, length(next_dists))

    # value <- Euclid(next_dists, 5*projections)
    value <- next_dists + 1*projections

    candidate <- next_points[which.min(value),"run"]
    xy[candidate, "idx"] <- i
      
  }

  curve$stream_order <- xy[, "idx"]
    
  return(curve)

}

test_curve <- get_stream_linecurve(vhag = 9574, segment_rank = 218821) %>%
    filter(rank > 20, rank < 26)
head(test_curve, 16)

corrected_curve <- correct_curve_arrangement(test_curve) %>%
  arrange(stream_order)

# cbind(test_curve$lseq)

test_curve %>%
  ggplot(aes(x, y)) +
    geom_point() +
    geom_path() +
    geom_path(aes(corrected_curve$x, corrected_curve$y), color = "red")

# plot(corrected_curve$rank)

```

The good news is that my solution mathes the VHAG default in the test case.


## stream batch processing


```{r stream-data-assembly}
# vhag <- 9574
# segment_rank <- 218821
# unit_id <- "9574_218821"
#
# unit_id <- "47203_84627"

get_stream_curve_properties <- function(unit_id) {

  vhag <- stringr::str_split(unit_id, "_")[[1]][1]
  segment_rank <- as.numeric(stringr::str_split(unit_id, "_")[[1]][2])

  # extract the curve  
  curve <- get_stream_pointcurve(vhag = vhag, segment_rank = segment_rank)

  curve <- get_all_curve_measures(
    curve,
    normed = TRUE,
    smooth = 5
  )

  segment <- curve %>%
    filter(rank == 0) %>%
    select(-rank) %>% 
    mutate(unit_id = unit_id)

  return(segment)
    
}

```


```{r stream-batch}
#| eval: true

stream_list <- stratum_units_grts_aquatic_gw_spsamples_spares %>%
  filter(sample_support_code == "watercourse_segment") %>%
  pull(unit_id)

# for (uid in stream_list) {
#   message(uid)
#   get_stream_curve_properties(uid)
# }

stream_data <- bind_rows(lapply(stream_list, FUN = get_stream_curve_properties))
kableprint(stream_data)
```


Strategy to continue (TODO):

- [X] Per sample point: go into `direction * normal`.
- [X] Mark target area aligned towards upstream.
- [X] Consider also incorporating slope; at least check consistency.

## stream determine target area

With the info aggregated by `get_stream_curve_properties`, we can decide on an alternative placement area.

```{r stream-target-area}
get_stream_target_area <- function(unit_id, offset_m = 8, side_m = 16) {

  # get stream info
  stream_info <- get_stream_curve_properties(unit_id)

  # reference vectors
  segment_point <- stream_info[c("x", "y")]

  # normal, in the direction of curvature
  curvature <- stream_info[["curv_smth"]]
  if(is.na(curvature)) curvature <- stream_info[["curv"]]
  normal_unit_vector <- sign(curvature) * stream_info[c("nx", "ny")]

  # tangent and difference vectors
  diff_unit_vector <- stream_info[c("dx", "dy")]
  diff_unit_vector <- diff_unit_vector / sqrt(sum(diff_unit_vector^2))
  tangent_unit_vector <- stream_info[c("tx", "ty")]

  # check the strenght of the slope in the area
  flow_vector <- calculate_flow_direction(
    sf::st_as_sf(segment_point, coords = c("x", "y"), crs = 31370),
    flow_range = 96,
    flow_cellsize = 16,
    save_plot_filepath = here::here("figures", sprintf("%s.png", unit_id))
  )

  # compare curvature and elevation-slope
  curv_sign <- -1 # normally, we go opposite of curvature direction

  # check whether flow is in direction of the normal, or not
  direction_scalar <- as.matrix(normal_unit_vector) %*% as.matrix(flow_vector)
  same_direction <- 0 < direction_scalar

  if (!same_direction) {
    # we normally go in the direction of curvature
    # except if
    #   - the flow vector magnitude is large
    #   - curvature is low in magnitude
    # heuristics: 2*curvature seems to be more relevant

    flow_magnitude <- sqrt(sum(flow_vector^2))
    if (flow_magnitude > 2 * abs(curvature)) {
      curv_sign <- +1 # if flow projection to normal is large, switch sign
    }
  }
    
  # go around the square
  direction_vector <- tangent_unit_vector
  points <- segment_point + curv_sign * offset_m * normal_unit_vector
  points <- bind_rows(points, points[1, ] - side_m * direction_vector)
  points <- bind_rows(points, points[2, ] + curv_sign * side_m * normal_unit_vector)
  points <- bind_rows(points, points[3, ] + side_m * direction_vector)
  points <- bind_rows(points, points[4, ] - curv_sign * side_m * normal_unit_vector) # back to start

  target <- points %>% sf::st_as_sf(coords = c("x", "y"), crs = 31370)

  target <- st_combine(target) %>% st_cast("POLYGON", warn = FALSE)
  return(sf::st_sf(data.frame(unit_id = unit_id, geom=target)))
}

```


```{r stream-test-curvature-vs-flow}

create_sf_vector <- function(pt, vec, unit_id) {
  line <- as.data.frame(rbind(pt, pt + vec)) %>%
    setNames(c("x", "y")) %>% 
    sf::st_as_sf(coords = c("x", "y"), crs = 31370)
  
  line <- sf::st_sf(st_combine(line) %>% st_cast("LINESTRING"))
  return(sf::st_sf(data.frame(unit_id = unit_id, geom=line)))
}

# TODO try unit_id <- "9574_218856"
# TODO crashing unit_id <- "9574_218829", 837, ...
sample_unit_id <- "9574_218821"
test_targets <- get_stream_target_area(sample_unit_id, offset_m = 10, side_m = 20)

curvs <- NA
flows <- NA
for (i in seq(771, 852, 5)) {
  unit_id <- sprintf("9574_218%03.0f", i)
  # message(unit_id)
  test_targets <- bind_rows(
    test_targets,
    get_stream_target_area(unit_id, offset_m = 10, side_m = 20)
    )

  # flow and curvature
  scale <- 100
  stream_info <- get_stream_curve_properties(unit_id)
  segment_point <- stream_info[c("x", "y")]

  # normal, in the direction of curvature
  curvature <- stream_info[["curv_smth"]]
  if(is.na(curvature)) curvature <- stream_info[["curv"]]
  normal_curvature <- 2*scale * curvature * stream_info[c("nx", "ny")]
  if (any(is.na(curvs))) {
    curvs <- create_sf_vector(segment_point, normal_curvature, unit_id)
  } else {
    curvs <- bind_rows(curvs, create_sf_vector(segment_point, normal_curvature, unit_id))
  }

  # check the strenght of the slope in the area
  flow_vector <- scale * calculate_flow_direction(
    sf::st_as_sf(segment_point, coords = c("x", "y"), crs = 31370),
    flow_range = 128,
    flow_cellsize = 8,
    save_plot_filepath = here::here("figures", sprintf("%s.png", unit_id))
  )

  if (any(is.na(flows))) {
    flows <- create_sf_vector(segment_point, flow_vector, unit_id)
  } else {
    flows <- bind_rows(flows, create_sf_vector(segment_point, flow_vector, unit_id))
  }
  
}

test_curve <- sf::st_as_sf(
  get_stream_pointcurve(vhag = 9574, segment_rank = 218821),
  coords = c("x", "y"),
  crs = 31370
  ) %>%
  filter(rank >= -52, rank < 36) %>% 
  mutate(selected = ((rank - 770) %% 5) == 0)

m1 <- mapview(test_curve, zcol = "selected")
test_targets$label <- "placement target area"
m2 <- mapview(test_targets, col.regions = "red", zcol = "label")

flows$label <- "flow direction"
m3 <- mapview(flows, color = "darkblue", zcol = "label")
curvs$label <- "curvature direction"
m4 <- mapview(curvs, color = "orange", zcol = "label")
m1+m2+m3+m4

```


## Summary: Streams

- Target is placed depending on curvature and elevation/slope.
- Usually, those seem consistent.
- Elevation has to overrule curvature.
- Area is aligned upstream from segment point.

