---
title: "Data Sources to Categorize Site Accessibility"
date: "2025-04-25"
format:
  html:
    toc: true
    html-math-method: katex
    code-fold: false
    embed-resources: true
knitr:
  opts_chunk:
    echo: true
---



```{r libraries}

void <- suppressPackageStartupMessages

conflictRules("n2khab", exclude = c("read_schemes", "read_scheme_types"))
library("stringr")     |> void() # string ragging
library("dplyr")       |> void() # our favorite data wrangling toolbox
library("tidyr")       |> void() # data preparation and rearrangement
library("googledrive") |> void() # google drive data to/fro
library("inbospatial") |> void() # convenience functions for wfs and other queries
library("sf")          |> void() # spatial feature processing
library("terra")       |> void() # spatial raster data
# library("qgisprocess") |> void() # interface to the procedures of our favorite GIS software
library("mapview")     |> void() # show spatial features on a map
library("n2khab")      |> void() # n2khab data and common functions
library("n2khabmon")   |> void() # monitoring schemes for natura2000 habitats

# print sample from sf objects
kableprint <- function(df, show_rows = 5) {
  knitr::kable(df[sample(1:nrow(df), show_rows), ])
}
```


# strategy:


## procedural:

- (i) get sample locations
- (ii) get aquatic bodies
  - surfs, streams, springs
  - ensure 31370
  - buffers: r₁ = 20m, r₂ = 40m
- target distance from surface water edge: r = 30m
- query dhmv(xᵢ | 1m resolution) ∀ xᵢ < r₂
  - calculate gradient direction
  - take wedge of α=π/8
  - complication: Flanders is flat; optionally query a wider range


## special situation:

- stream into/out of surface water body


## cases:

- sample x ⊂ r₁ ⇒ place anywhere around
- sample r₁ < x < r ⇒ move to target distance r


## exploration:

- filter an example area


## complication anticipation:

- Flanders is relatively flat
- water redistributes under the influence of gravity

⇒ elevation gradient below detection limit?


# data

## Assembling Aquatic Habitat Types

### data consistence

```{r datasource-consistency}
#' data source version persistence
#'
#' Manually check data source versions (something to be automated by n2khab
#' package in the future, based on preset versions)
#'
confirm_n2khab_data_consistency <- function() {

  # required for the pipe operator 
  stopifnot("magrittr" = require("magrittr"))

  # the checksums of working data versions (as of 20250501)
  # - watersurfaces_hab: version watersurfaces_hab_v6
  # - habitatstreams: version habitatstreams_2023
  # - habitatsprings: version habitatsprings_2020v2
  # - flanders: version "flanders_2018-05-16"
  reference_checksum <- c(
    flanders.dbf = "d21a599325723682",
    flanders.prj = "2f10404ffd869596",
    flanders.shp = "72fff53084b356be",
    flanders.shx = "1880e141bbcdc6ca",
    habitatsprings.geojson = "7268c26f52fcefe4",
    habitatstreams.dbf = "dee7a620e3bcae0a",
    habitatstreams.lyr = "a120f92d80c92a3a",
    habitatstreams.prj = "7e64ff1751a50937",
    habitatstreams.shp = "5a7d7cddcc52c5df",
    habitatstreams.shx = "b2087e6affe744f4",
    habitatstreams.sld = "2f192b84b4df99e9",
    watersurfaces_hab.gpkg = "e2920c4932008387"
  )
    
  # for comparison: checksums of current files on disk
  status_checksum <- file.path(
      n2khab::locate_n2khab_data(),
      c(
        "20_processed/watersurfaces_hab",
        "10_raw/habitatsprings",
        "10_raw/habitatstreams",
        "10_raw/flanders"
      )
    ) %>%
    list.files(full.names = TRUE) %>%
    n2khab::xxh64sum()
    
  # per filename, check whether checksums match
  check_identical_checksum <- function (filename) {

    # the check
    file_check <- identical(
        reference_checksum[filename],
        status_checksum[filename]
      )

    # more verbose error upon mismatch
    if (!file_check) {
      message(paste0(
        "ERROR: file `",
        filename,
        "` changed on disk.",
        collapse = "") )
      }

    # stop or return TRUE
    return(is.null(
      stopifnot(file_check)
    ))
    
  }

  # check all files
  check <- all(sapply(names(reference_checksum), FUN = check_identical_checksum))

  # confirm correctness of all n2khab data files
  if (check) message("All n2khab data files match the recorded state.")
  
} # /confirm_n2khab_data_consistency


# apply the function
confirm_n2khab_data_consistency()

```


### watersurfaces present in the n2khab type list

```{r load-watersurface-habitats}

# reading scheme and type of target populations
n2khab_targetpops <-
  read_scheme_types() %>%
  select(scheme, type)

# list of distinct types
n2khab_types <-
  n2khab_targetpops %>%
  distinct(type) %>%
  arrange(type)

# `wsh` is the watersurface map of Flanders (https://doi.org/10.5281/zenodo.3386857)
wsh <- read_watersurfaces_hab(interpreted = TRUE)

# we are interested in the types which are part of the n2khab list
wsh_occ <-
  wsh$watersurfaces_types %>%
  # in general we restrict types using an expanded type list tailored to the
  # type levels present in data sources, but for the aquatic types expansion and
  # subsequent collapse of types are redundant steps
  semi_join(n2khab_types, join_by(type))

# of the focus-type watersurface polygons, we extract the polygon id
wsh_pol <-
  wsh$watersurfaces_polygons %>%
  semi_join(wsh_occ, join_by(polygon_id)) %>%
  select(polygon_id)

kableprint(wsh_pol) # polygon id of the watersurface polygons of interest
```


### Streams

Temporary approach to generate `segm_3260` (i.e. it will miss a part and some may be false positives)
(unit ID defined by `unit_id`)

```{r load-streams}

# habitat 3260 from
#     Biologische Waarderingskaart en Natura 2000 Habitatkaart
#     https://doi.org/10.21436/inbor.96375305
# ... are the streams
habstream <- read_habitatstreams()

# for those streams, we use the 100m line segments
# applying spatial supsetting (intersect!) with sf_x[sf_y, ]
#   not well documented in https://r-spatial.github.io/sf/reference/sf.html
#   -> geocomputation with R https://r.geocompx.org/spatial-operations#spatial-subsetting
#   habstream <- read_habitatstreams()
#   seg_all <- read_watercourse_100mseg(element = "lines")
#   seg_reference <- seg_all[habstream, , op = sf::st_intersects]
#   seg_test <- seg_all[lengths(sf::st_intersects(seg_all, habstream, sparse = TRUE)) > 0, ]
#   identical(seg_reference, seg_test)
segm_3260 <-
  read_watercourse_100mseg(element = "lines")[habstream, ] %>%
  unite(unit_id, vhag_code, rank) # tidyr::unite string concatenation

kableprint(segm_3260) # unique identifier for line segments

```


### Springs
Generating `habspring_units_aquatic` (unit ID defined by `unit_id`)

```{r load-springs}

# creating a buffered version of Flanders
flanders_buffer <-
  read_admin_areas(dsn = "flanders") %>%
  st_buffer(40) # units: meter

# read in the spring habitat source
habspring_units_aquatic <-
  # following function will be adapted to support the latest version of the data
  # source (just released); for now use version habitatsprings_2020v2
  read_habitatsprings(units_7220 = TRUE) %>%
  # filtering for the spatial intersect with Flanders
  .[flanders_buffer, ] %>%
  # and excluding "mire" type
  filter(system_type != "mire")

# all spring locations (note: full data, not just ID)
kableprint(habspring_units_aquatic)
```


## load the sample


### google authentification

Currently, the latest version of the sample is distributed via an `.RData` file on the google drive.

```{r google-auth}
# Setup for googledrive authentication. Set the appropriate env vars in
# .Renviron and make sure you ran drive_auth() interactively with these settings
# for the first run (or to renew an expired Oauth token).
# See ?gargle::gargle_options for more information.
google_drive_init <- function() {
  if (Sys.getenv("GARGLE_OAUTH_EMAIL") != "") {
    options(gargle_oauth_email = Sys.getenv("GARGLE_OAUTH_EMAIL"))
  }
  if (Sys.getenv("GARGLE_OAUTH_CACHE") != "") {
    options(gargle_oauth_cache = Sys.getenv("GARGLE_OAUTH_CACHE"))
  }
}

# tipps for paranoid linux terminal users (non-interactive R):
# - point your oauth cache to a tomb https://dyne.org/tomb
# - do not forget to open the tomb prior to starting the R session

google_drive_init()
```



### load/restore sample data

Download the sample data (unless it is already there).

```{r sample-data-download}
# latest (20250506):
#   target_sample_filepath <- file.path("./data", "objects_for_aq_piezometers_panfl_pan5.RData")
#   googledrive::as_id("1Z93w-C3XRQ8756W3835JPfxggGEstjKR"),


force_reload_sample <- FALSE
target_sample_filepath <- file.path("./data", "objects_for_aq_piezometers_panfl_pan5.RData")

if (force_reload_sample || !file.exists(target_sample_filepath)) {
  googledrive::drive_download(
    googledrive::as_id("1Z93w-C3XRQ8756W3835JPfxggGEstjKR"),
    path = target_sample_filepath,
    overwrite = TRUE
  )
}

# deprecated: 
#   target_sample_filepath <- file.path("./data", "objects_for_aq_piezometers_panfl_pan5.RData")
#   googledrive::as_id("1Z93w-C3XRQ8756W3835JPfxggGEstjKR"),
#   target_sample_filepath <- file.path("./data", "objects_panflpan5.RData")
#   googledrive::as_id("1a42qESF5L8tfnEseHXbTn9hYR1phqS-S"),


# load the data into a new environment
env_extradata <- new.env()
load(target_sample_filepath, envir = env_extradata)
ls(envir = env_extradata)

for (var in c(
  "units_non_cell_n2khab_grts",
  "stratum_units_non_cell_n2khab",
  "scheme_moco_ps_stratum_sppost_spsamples_spares_sf"
  )) {
  tryCatch(
  {stopifnot(exists(var, envir = env_extradata))},
  error = function(wrnmsg) {
    message(paste0(
      "The variable ", var,
      " does not exist in environment `env_extradata`.",
      collapse = "")
    )
  }
  )
}

```

(adjusted to read full POC `.RData`, [see here](https://github.com/inbo/n2khab-mne-design/blob/7a08ab9d36669d3a5b64d12b8bc35ff7c7a6a5d1/100_design_common/010_prototyping_sampling_and_revisit_design/helper_scripts/support_dcp_and_fieldwork.R))


restore sample data structure
Below object can be used to filter the foregoing geospatial objects, taking
into account that: rows with ...

- `sample_support_code == watersurface` relate to the IDs in `wsh_pol`
- `sample_support_code == watercourse_segment` relate to the IDs in `segm_3260`
- `sample_support_code == spring` relate to the IDs in `habspring_units_aquatic`

```{r sample-data-join}

stratum_units_grts_aquatic_gw_spsamples_spares <-
  # units per stratum:
  get("stratum_units_non_cell_n2khab", envir = env_extradata) %>%
  # joining GRTS address per unit. A few non-unique GRTS addresses exist, hence
  # 'many-to-one'. See further.
  inner_join(
    get("units_non_cell_n2khab_grts", envir = env_extradata),
    join_by(sample_support_code, unit_id),
    relationship = "many-to-one",
    unmatched = "error"
  ) %>%
  filter(
    # other 'non-cell' types exist so these must be dropped:
    sample_support_code %in% c(
      "watersurface",
      "watercourse_segment",
      "spring"
    ),
    # terrestrial spring units must also be excluded:
    unit_id %in% habspring_units_aquatic$unit_id |
      sample_support_code != "spring"
  ) %>%
  rename(grts_address_final = grts_address) %>%
  # join with samples ('sample_status' defines whether location is 'in the
  # sample' or is a 'spare unit' (spare units = a bunch of 'next' GRTS addresses
  # in the available GRTS series for a stratum))
  inner_join(
    get(
      "scheme_moco_ps_stratum_sppost_spsamples_spares_sf",
      envir = env_extradata
    ) %>%
      st_drop_geometry() %>% # geom will be used below
      # only use the samples of groundwater schemes
      filter(str_detect(scheme, "^GW")) %>%
      rename(grts_address_drawn = grts_address) %>%
      # collapse module combos and schemes; hereby select the 'prior'
      # sample_status ("in_sample") across module combos and schemes:
      summarize(
        sample_status = sample_status %>% droplevels() %>% levels() %>%  first(),
        .by = c(
          stratum,
          grts_address_drawn,
          grts_address_final
        )
      ) %>%
      mutate(sample_status = factor(sample_status)),
    join_by(stratum, grts_address_final),
    # A few non-unique GRTS addresses exist, hence 'many-to-one'. We will apply
    # a quick-fix below to meet the requirement of 'one unit sampled per GRTS
    # address', but at least the selection will need further alignment with the
    # (likewise) MHQ solution (to be continued).
    relationship = "many-to-one",
    unmatched = "drop"
  ) %>%
  arrange(sample_support_code, stratum, grts_address_drawn, unit_id) %>%
  # for now, de-duplicate units with the same GRTS address by selecting the 1st
  slice(1, .by = c(stratum, sample_support_code, grts_address_final)) %>%
  select(-grts_address_drawn)


# grts address and stratum of all units which are in the target category
# (i.e. "watersurface", "watercourse_segment", "non-terrestrial spring")
kableprint(stratum_units_grts_aquatic_gw_spsamples_spares)

```


::: {.callout-caution}
REMINDER:
we de-duplicate units with the same GRTS address by selecting the 1st.
:::


```{r recover-geometry}
geometry_link <- get(
      "scheme_moco_ps_stratum_sppost_spsamples_spares_sf",
      envir = env_extradata
    ) %>%
    sf::st_transform(31370) %>% 
    select(grts_address) %>%
    distinct

data <- geometry_link %>%
  right_join(
    stratum_units_grts_aquatic_gw_spsamples_spares,
  by = join_by(grts_address == grts_address_final),
  relationship = "one-to-many",
  unmatched = "drop"
  )

mapview(data)
```


### filter test data

generate a small test dataset:
unit_id ⊂ {`LIMDPB`, `LIMGNK`}


```{r filter-test-data}
test_data <- data %>%
  filter(stringr::str_detect(unit_id, "^LIMDPB|^LIMGNK"),
         sample_status == "in_sample")

mapview(test_data)
```

:::{.callout-warning}
TODO: 

- There are some points which appear not to be wet (e.g. `LIMGNK0062`). This might have to do with GRTS raster ["partial volumes"]("https://en.wikipedia.org/wiki/Partial_volume_(imaging)").
- Others are vast (`LIMGNK0055`); will be challenging to get elevation gradient.
- `LIMGNK0010` might serve as an example.
:::

```{r google-satellite}
# mapviewGetOption("basemaps")
test_data %>%
  mutate(
    highlight = unit_id %in% c("LIMGNK0062", "LIMGNK0055", "LIMGNK0010")
    ) %>%
  mapview(
    map.types = c("Esri.WorldImagery", "OpenStreetMap"),
    col.regions = c("snow", "yellow"),
    zcol = "highlight",
    burst = TRUE
  )
```


# Case Study: LIM*@DHMV

**Natuurreservaat "De Maten"**, nabij Genk.


## query dhmv


```{r query-dhmv}
xy <- as.data.frame(
    sf::st_coordinates(test_data)
  ) %>%
  rename_with(tolower)

margin <- 256 # m
flow_cellsize <- 32 # m
bbox <- sf::st_bbox(
   c(xmin = min(xy["x"]) - margin,
     xmax = max(xy["x"]) + margin,
     ymin = min(xy["y"]) - margin,
     ymax = max(xy["y"]) + margin
     ),
   crs = sf::st_crs(31370)
)
test_raster <- inbospatial::get_coverage_wcs(
  wcs = "dhmv",
  bbox = bbox,
  layername = "DHMVII_DTM_1m",
  version = "2.0.1",
  wcs_crs = "EPSG:31370",
  resolution = 1
)

# plot map
plot(test_raster, col = gray.colors(256)
     # ylab = sprintf("cluster %i (%s)", cluster_idx, regions)
     )
points(xy[["x"]], xy[["y"]], pch = 21, col = "black")
points(xy[["x"]], xy[["y"]], pch = 16, col = "yellow")
# title(sprintf("cluster %i", cluster_idx))

```



## example location: `LIMGNK0010`

```{r filter-test-location}
test_location <- test_data %>%
  filter(
    unit_id == "LIMGNK0010"
    )

test_buffer <- test_location %>%
  sf::st_buffer(margin) 
sub_raster <- raster::crop(test_raster, raster::extent(test_buffer))

plot(sub_raster, col = gray.colors(256))
```



## flow direction


Prior (by Hans / via `qgisprocess`):

- <https://docs.google.com/presentation/d/1mF9Nd3sXwsZmCYLmAE3vsRYNO7sX4p0ojro9-szMmJY/edit#slide=id.g2e7cd3adab0_21_25>


Whitebox Tools / Hydrological Analysis / FD8 flow pointer

- <https://www.whiteboxgeo.com/manual/wbt_book/available_tools/hydrological_analysis.html#Fd8Pointer>


R / cran / whitebox / `wbt_d8_pointer`

- <https://rdrr.io/cran/whitebox/man/wbt_d8_pointer.html>
- <https://whiteboxr.gishub.org/reference/wbt_d8_pointer.html>


- <https://github.com/inbo/mas-piloot/blob/29b2589baa9b822449624ff207eb53131b286568/src/markdown/general/verkenning_macroinvertebraten_map_vmm.Rmd#L459>


```{r qgis-find-algorithm}
#| eval: false

qgisprocess::qgis_algorithms() %>%
  filter(stringr::str_detect(tolower(algorithm_title), "flow"))
  # filter(stringr::str_detect(tolower(algorithm_title), "pointer"))
  # filter(stringr::str_detect(tolower(algorithm_title), "buffer"))

```

- "grass:r.gwflow",
- "grass:r.flow",


this errors:

```{r qgisprocess-d8-pointer}
#| eval: false

test_flow <- qgisprocess::qgis_run_algorithm(
  "grass:r.flow",
  elevation = sub_raster,
  # output = here::here("data", "dhmvii_dtm_50m_d8_pointer.tif"),
  .quiet = TRUE)
```

  ... but maybe qgis can be skipped.
  
- either via `rgrass`: <https://grasswiki.osgeo.org/wiki/R_statistics/rgrass>
- or directly in terra? <https://rdrr.io/cran/terra/man/terrain.html>


```{r terra-slope}
slope <- terra::terrain(
  sub_raster,
  v = "slope"
  )
plot(slope)
```

```{r terra-flowdir}
flow <- terra::terrain(
  sub_raster,
  v = "flowdir",
  neighbors = 4
  )
plot(flow)
```


nice, but maybe too many details.

```{r resample-coarse}
n_grid <- as.integer(margin/flow_cellsize)

xtnt <- setNames(
  as.vector(raster::extent(test_buffer)),
  c("xmin", "xmax", "ymin", "ymax"))

coarse_grid <- rast(
  nrows = n_grid, ncols = n_grid,
  xmin = xtnt[["xmin"]],
  xmax = xtnt[["xmax"]],
  ymin = xtnt[["ymin"]],
  ymax = xtnt[["ymax"]],
  )
crs(coarse_grid) <- "EPSG:31370"
x <- resample(
  sub_raster,
  coarse_grid,
  method = "lanczos"
  # method = "bilinear"
)
plot(x)
```

```{r resample-slope}
slope <- terra::terrain(
  x,
  v = "slope"
  )
plot(slope)

```

```{r resample-flow}
flow <- terra::terrain(
  x,
  v = "flowdir",
  neighbors = 8
  )
plot(flow)
```

```
      32  64  128
      16   x    1
       8   4    2

log2:  5   6    7
       4   x    0
       3   2    1
       
2*pi/8 = 0.8
pi:  4.0 3/2pi 5.6
      pi    x    0
     2.4 1/2pi 0.8

|-------|--------|---------|
| α     | cos(α) | -sin(α) |
|-------|--------|---------|
| 0     |    1   |    0    |
| pi/2  |    0   |   -1    |
| pi    |   -1   |    0    |
| 3pi/2 |    0   |   +1    |
| 2pi   |    1   |    0    |
|-------|--------|---------|
| coord |   *x*  |   *y*   |
|-------|--------|---------|

```

- <https://search.r-project.org/CRAN/refmans/pracma/help/quiver.html>

(based on arrows)

```{r arrows}
#| eval: false
x <- stats::runif(12); y <- stats::rnorm(12)
i <- order(x, y); x <- x[i]; y <- y[i]
plot(x,y, main = "arrows(.) and segments(.)")
## draw arrows from point to point :
s <- seq(length(x)-1)  # one shorter than data
graphics::arrows(x[s], y[s], x[s+1], y[s+1], col = 1:3)
```

```{r flow-to-angle}
# positions <- as(raster::raster(coarse_grid), "SpatialGridDataFrame")
px <- raster::rasterToPoints(raster::raster(flow))[,1]
py <- raster::rasterToPoints(raster::raster(flow))[,2]
pz <- raster::rasterToPoints(raster::raster(flow))[,3]
# pz[1] <- 2^1
# pz[1<n<9] <- 2^n 
# pz[9] <- 0
direction <- 2*pi/8 * log2(pz)
direction[!is.finite(direction)] <- NA 

dx <- +1*cos(direction)
dy <- -1*sin(direction)

# directions <- as.matrix(flow, wide = TRUE)
```

```{r quiver-plot}
# plot(px, py, cex = 1)
plot(slope)
pracma::quiver(
  x = px,
  y = py,
  u = dx,
  v = dy,
  scale = 3,
  col = "darkorange"
  )

```

```{r average-direction}
nonnan <- function(vec) vec[!is.na(vec)]
nanmean <- function(vec) mean(nonnan(vec))
print(paste0(nanmean(dx), ", ", nanmean(dy)))

```

```{r radius}
nonnan <- function(vec) vec[!is.na(vec)]
nanmean <- function(vec) mean(vec[!is.na(vec)])
euclid <- function(x, y) sqrt(x^2 + y^2)
within_radius <- function(x, y, r = 128) {
  dist <- euclid(
    nonnan(x) - nanmean(x),
    nonnan(y) - nanmean(y)
  )
  return(dist < r)
}
sel <- within_radius(px, py, r = margin-flow_cellsize) # TODO discuss radius

plot(slope)
pracma::quiver(
  x = px[sel],
  y = py[sel],
  u = dx[sel],
  v = dy[sel],
  scale = 3,
  col = "darkorange"
  )

print(paste0(nanmean(dx[sel]), ", ", nanmean(dy[sel])))
```


```{r slope-weighted-average}
nancumsum <- function (vec, weight, selection) {

  vec <- as.matrix(vec)
  weight <- as.matrix(weight)
  selection <- as.matrix(selection)

  nans <- is.na(vec) | is.na(weight) | is.na(selection)
  vec <- vec[!nans]
  weight <- weight[!nans]
  selection <- selection[!nans]

  return(sum(vec[selection] * weight[selection]) / sum(weight[selection]))
}

print(paste0(nancumsum(dx, slope, sel), ", ", nancumsum(dy, slope, sel)))

```



- [X] get grids of 32m
- [X] idea: slope-weighted average direction
- [X] test other interpol methods (not matter much)


# Generalization

- get flow direction
- based on DHMV
- within given radius 
- ... and given grid size


```{r flow-gradient-general-function}

#' Calculate flow direction
#'
#' Calculate the putative flow direction at a given point
#' based on the elevation/slope in the buffer area around it.
#' All calculations will be performed in CRS 31370, hence the output
#' flow vector will be in meters.
#' 
#' @details this is the slope-averaged flow direction between
#' cells in a coarse raster grid within a given radius around the location.
#' It uses `terra::terrain(coarse_raster, v = "flowdir", neighbors = 8)`.
#'
#' @param location the point (or polygon) of interest;
#'        an `sf` object of which the `sf::st_coordinates` are used.
#' @param buffer_width the buffer extent (in meters) around the location, 
#'        which is used to query elevation and calculate flow.
#'        Units are those of the coordinates.
#' @param flow_cellsize the width of a cell in the resampled raster
#'        across which elevation is averaged to calculate flow.
#'        Units are those of the coordinates.
#' @param save_plot_filepath if this is not NA, a summary map of the
#'        flow calculation will be saved as "png" image to the given path.
#' @return c(dx,dy) vector (in meters) of the average flow direction in a
#'        circular area around the location.
#'
calculate_flow_direction <- function(
    location,
    buffer_width = 256, flow_cellsize = 32,
    save_plot_filepath = NA) {

  # location_raw <- location # currently not necessary to store the data in raw CRS

  # all calculations will be performed in CRS 31370
  location <- sf::st_transform(location, 31370)

  # only the coordinates are relevant ("xy", but could be "lon/lat")
  xy <- as.data.frame(
      sf::st_coordinates(location)
    ) %>%
    rename_with(tolower)
  
  ### Query DHMV
  # (elevation model of Flanders)
  # within a buffer area
  bbox <- sf::st_bbox(
     c(xmin = min(xy[1]) - buffer_width,
       xmax = max(xy[1]) + buffer_width,
       ymin = min(xy[2]) - buffer_width,
       ymax = max(xy[2]) + buffer_width
       ),
     crs = sf::st_crs(31370)
  )

  location_raster <- inbospatial::get_coverage_wcs(
    wcs = "dhmv",
    bbox = bbox,
    layername = "DHMVII_DTM_1m",
    version = "2.0.1",
    wcs_crs = "EPSG:31370",
    resolution = 1
  )
  
  ### Resample
  # to get a coarse grid
  n_grid <- as.integer(buffer_width/flow_cellsize)
  
  # resample within the buffer range
  coarse_grid <- terra::rast(
    nrows = n_grid, ncols = n_grid,
    xmin = min(xy[1]) - buffer_width,
    xmax = max(xy[1]) + buffer_width,
    ymin = min(xy[2]) - buffer_width,
    ymax = max(xy[2]) + buffer_width
    )
  terra::crs(coarse_grid) <- "EPSG:31370"
  coarse_raster <- terra::resample(location_raster, coarse_grid,
    method = "lanczos" # method = "bilinear"
  )
  
  ### calculations
  # slope and flow, using terra::terrain
  slope <- terra::terrain(coarse_raster, v = "slope")
  flow <- terra::terrain(coarse_raster, v = "flowdir", neighbors = 8)
  
  # extract flow axes
  flow_points <- raster::rasterToPoints(raster::raster(flow))
  fpx <- flow_points[,1]
  fpy <- flow_points[,2]
  fpz <- flow_points[,3]
  
  # convert direction to angles...
  direction <- 2*pi/8 * log2(fpz)
  direction[!is.finite(direction)] <- NA 
  
  # ... convert direction angles to "dx", "dy"
  dx <- +1*cos(direction)
  dy <- -1*sin(direction)
  
  # helper functions:
  # remove nan
  nonnan <- function(vec) vec[!is.na(vec)]
  # mean, excluding NAs
  nanmean <- function(vec) mean(nonnan(vec))

  # Euclidean length of the vector
  euclid <- function(x, y) sqrt(x^2 + y^2)

  # filter coordinates within radius
  within_radius <- function(x, y, r = 128) {
    dist <- euclid(
      nonnan(x) - nanmean(x),
      nonnan(y) - nanmean(y)
    )
    return(dist < r)
  }
      
  # calculate the average flow, but weighted and filtered
  average_flow <- function (vec, weight, selection) {
  
    # simplify input data types
    vec <- as.matrix(vec)
    weight <- as.matrix(weight)
    selection <- as.matrix(selection)
  
    # disregard NA's
    nans <- is.na(vec) | is.na(weight) | is.na(selection)
    vec <- vec[!nans]
    weight <- weight[!nans]
    selection <- selection[!nans]
  
    # return the weighted average of the vector
    return(sum(vec[selection] * weight[selection]) / sum(weight[selection]))
  }
  
  ### compute average flow of coarse cells
  sel <- within_radius(fpx, fpy, r = buffer_width - flow_cellsize) 
  flow_vector <- c(average_flow(dx, slope, sel), average_flow(dy, slope, sel))

  ### optionally store a quiver plot on a map for vizualization
  if (!is.na(save_plot_filepath)) {

    png(save_plot_filepath,
      width = 120,
      height = 120,
      units = "mm",
      res = 300
    )

    # raster background
    plot(location_raster)

    # flow per cell
    pracma::quiver(
      x = fpx[sel],
      y = fpy[sel],
      u = dx[sel],
      v = dy[sel],
      scale = 8,
      col = "gray"
      )

    # average flow
    pracma::quiver(
      x = xy[[1]],
      y = xy[[2]],
      u = flow_cellsize * flow_vector[[1]],
      v = flow_cellsize * flow_vector[[2]],
      scale = 3,
      col = "darkorange"
    )

    dev.off()
  }
    
  return(flow_vector)

}


# exemplary execution
for (location_code in c("LIMGNK0062", "LIMGNK0055", "LIMGNK0010")) {
  test_location <- test_data %>% 
    filter(unit_id == location_code)
  
  print(
    paste0(
      location_code, ": ",
      paste0(
        calculate_flow_direction(
          test_location,
          buffer_width = 256,
          flow_cellsize = 32,
          save_plot_filepath = here::here("figures", sprintf("%s.png", location_code))
        ),
        collapse = ", "
      ),
      collapse = ""
    )
  )
}


# location <- test_location

```
